{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lesson15.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHmOKTkmu0XE",
        "colab_type": "text"
      },
      "source": [
        "##Exercise 1\n",
        "\n",
        "**Writing a simple neural network function**\n",
        "\n",
        "Given an input and weight as the input of the function, write a neural network function that return the prediction value as the result.\n",
        "\n",
        "The input is is a list of random numbers but with small difference between each numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj_wAq6ovuCq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c1285b0-c984-46c7-d7b7-89861313b585"
      },
      "source": [
        "weight = 0.1\n",
        "def neural_network(input, weight):\n",
        "  prediction = input * weight\n",
        "  return prediction\n",
        "\n",
        "number_of_items = [7.0, 7.2, 7.4, 7.8, 8.5]\n",
        "input = number_of_items[0]\n",
        "pred = neural_network(input, weight)\n",
        "print(pred)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7000000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxtCHx079qYb",
        "colab_type": "text"
      },
      "source": [
        "##Exercise 2\n",
        "**Writing a softmax function**\n",
        "\n",
        "1. Write a function that takes an input a list of numbers, and returns the list of values given by the softmax function.\n",
        "\n",
        "2. By using [keras](https://keras.io/activations/), write the softmax function.\n",
        "\n",
        "---\n",
        "$f(x_{i}) =\\frac{e^{x_{i}}}{\\sum_{j=0}^{k}{e^{x_{j}}}}    $\n",
        "\n",
        "where $i = 0,1,2,...k$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHzakn-u-Ifs",
        "colab_type": "code",
        "outputId": "68bdf0d0-db61-414e-a488-985e485d7ca5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#solution number 1\n",
        "import numpy as np\n",
        "\n",
        "def softmax(L):\n",
        "  exponential_L = np.exp(L)\n",
        "  sum_exponential_L = sum(exponential_L)\n",
        "  result = []\n",
        "  for i in exponential_L:\n",
        "    result.append(i*1.0/ sum_exponential_L)\n",
        "  return result\n",
        "\n",
        "L = [5,6,7]\n",
        "\n",
        "print(softmax(L))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.09003057317038046, 0.24472847105479764, 0.6652409557748219]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDXhZFnv9uV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#solution number 2\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense\n",
        "\n",
        "#create a model\n",
        "model = Sequential()\n",
        "\n",
        "#add the layer\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF3Zshx1DvPK",
        "colab_type": "text"
      },
      "source": [
        "##Exercise 3\n",
        "\n",
        "**Writing a cross entropy function**\n",
        "\n",
        "1. Write a function that takes as input two list Y, P and returns the float corresponding to their cross-entropy.\n",
        "2. Write the cross-entropy by using [keras](https://keras.io/losses/).\n",
        "\n",
        "\n",
        "---\n",
        "$H(y, \\hat{y}) = \\sum_{i}{y_i}log{\\frac{1}{\\hat{y_i}}}=-\\sum_{i}{y_i}log\\hat{y_i}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jndOH7OjGSd-",
        "colab_type": "code",
        "outputId": "2dc9c7ab-01c4-4458-d3d6-3c7b520c2215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#solution 1\n",
        "\n",
        "import numpy as np\n",
        "def cross_entropy(Y, P):\n",
        "    y = np.float_(Y)\n",
        "    p = np.float_(P)\n",
        "    return -np.sum(y * np.log(p)+ (1 - y) * np.log(1 - p))\n",
        "  \n",
        "Y = [1,0,1,1]\n",
        "P = [0.4, 0.6, 0.1, 0.5]\n",
        "\n",
        "print(cross_entropy(Y,P))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.828313737302301\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poRghvFnHKy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#solution 2\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer ='adam')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhACTSgvyUnx",
        "colab_type": "text"
      },
      "source": [
        "##Exercise 4\n",
        "\n",
        "**Creating a simple deep learning**\n",
        "\n",
        "This solution is referred from [Grokking Deep Learning Repo](https://github.com/iamtrask/Grokking-Deep-Learning/blob/master/Chapter6%20-%20Intro%20to%20Backpropagation%20-%20Building%20Your%20First%20DEEP%20Neural%20Network.ipynb).\n",
        "\n",
        "Imagine we have a traffic light (street lights):\n",
        "\n",
        "0 is red = stop\n",
        "1 is green = walk\n",
        "\n",
        "Calculate the prediction and training loss to predict the next color for the traffic light."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Iz8Gi6-zeey",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "b1bfb9cd-c30b-4b89-90c4-c4a574858437"
      },
      "source": [
        "import numpy as np\n",
        "weights = np.array([0.5,0.48,-0.7])\n",
        "alpha = 0.1\n",
        "\n",
        "streetlights = np.array( [ [ 1, 0, 1 ],\n",
        "                           [ 0, 1, 1 ],\n",
        "                           [ 0, 0, 1 ],\n",
        "                           [ 1, 1, 1 ],\n",
        "                           [ 0, 1, 1 ],\n",
        "                           [ 1, 0, 1 ] ] )\n",
        "\n",
        "walk_vs_stop = np.array( [ 0, 1, 0, 1, 1, 0 ] )\n",
        "\n",
        "input = streetlights[0] # [1,0,1]\n",
        "goal_prediction = walk_vs_stop[0] # equals 0... i.e. \"stop\"\n",
        "\n",
        "for iteration in range(30):\n",
        "    prediction = input.dot(weights)\n",
        "    error = (goal_prediction - prediction) ** 2\n",
        "    delta = prediction - goal_prediction\n",
        "    weights = weights - (alpha * (input * delta))\t\n",
        "\n",
        "    print(\"Error:\" + str(error) + \" Prediction:\" + str(prediction))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error:0.03999999999999998 Prediction:-0.19999999999999996\n",
            "Error:0.025599999999999973 Prediction:-0.15999999999999992\n",
            "Error:0.01638399999999997 Prediction:-0.1279999999999999\n",
            "Error:0.010485759999999964 Prediction:-0.10239999999999982\n",
            "Error:0.006710886399999962 Prediction:-0.08191999999999977\n",
            "Error:0.004294967295999976 Prediction:-0.06553599999999982\n",
            "Error:0.002748779069439994 Prediction:-0.05242879999999994\n",
            "Error:0.0017592186044416036 Prediction:-0.04194304000000004\n",
            "Error:0.0011258999068426293 Prediction:-0.03355443200000008\n",
            "Error:0.0007205759403792803 Prediction:-0.02684354560000002\n",
            "Error:0.0004611686018427356 Prediction:-0.021474836479999926\n",
            "Error:0.0002951479051793508 Prediction:-0.01717986918399994\n",
            "Error:0.00018889465931478573 Prediction:-0.013743895347199997\n",
            "Error:0.00012089258196146188 Prediction:-0.010995116277759953\n",
            "Error:7.737125245533561e-05 Prediction:-0.008796093022207963\n",
            "Error:4.951760157141604e-05 Prediction:-0.007036874417766459\n",
            "Error:3.169126500570676e-05 Prediction:-0.0056294995342132115\n",
            "Error:2.028240960365233e-05 Prediction:-0.004503599627370569\n",
            "Error:1.298074214633813e-05 Prediction:-0.003602879701896544\n",
            "Error:8.307674973656916e-06 Prediction:-0.002882303761517324\n",
            "Error:5.316911983140017e-06 Prediction:-0.0023058430092137705\n",
            "Error:3.4028236692096106e-06 Prediction:-0.0018446744073710164\n",
            "Error:2.177807148294282e-06 Prediction:-0.0014757395258968575\n",
            "Error:1.3937965749083403e-06 Prediction:-0.001180591620717486\n",
            "Error:8.920298079413378e-07 Prediction:-0.0009444732965739888\n",
            "Error:5.708990770825904e-07 Prediction:-0.0007555786372592799\n",
            "Error:3.653754093328579e-07 Prediction:-0.0006044629098074239\n",
            "Error:2.3384026197294315e-07 Prediction:-0.0004835703278458503\n",
            "Error:1.4965776766264926e-07 Prediction:-0.00038685626227663583\n",
            "Error:9.578097130409553e-08 Prediction:-0.00030948500982130867\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}